## SILVER LAYER SCRIPT

### DATA ACCESS USING APPLICATION (APP) 
from pyspark.sql.functions import *
from pyspark.sql.types import *

# https://learn.microsoft.com/en-us/azure/databricks/connect/storage/azure-storage
spark.hadoop.fs.azure.account.auth.type.<storage-account>.dfs.core.windows.net OAuth
spark.hadoop.fs.azure.account.oauth.provider.type.<storage-account>.dfs.core.windows.net org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
spark.hadoop.fs.azure.account.oauth2.client.id.<storage-account>.dfs.core.windows.net <application-id>
spark.hadoop.fs.azure.account.oauth2.client.secret.<storage-account>.dfs.core.windows.net {{secrets/<secret-scope>/<service-credential-key>}}
spark.hadoop.fs.azure.account.oauth2.client.endpoint.<storage-account>.dfs.core.windows.net https://login.microsoftonline.com/<directory-id>/oauth2/token

### DATA LOADING
#### Read Data
df_cal = spark.read.format('csv')\
    .option("header", True)\
    .option("inferSchema", True)\
    .load('abfss://bronze@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Calendar')

df_cus = spark.read.format('csv')\
    .option("header", True)\
    .option("inferSchema", True)\
    .load('abfss://bronze@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Customers')

df_procat = spark.read.format('csv')\
    .option("header", True)\
    .option("inferSchema", True)\
    .load('abfss://bronze@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Product_Categories')

df_pro = spark.read.format('csv')\
    .option("header", True)\
    .option("inferSchema", True)\
    .load('abfss://bronze@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Products')

df_ret = spark.read.format('csv')\
    .option("header", True)\
    .option("inferSchema", True)\
    .load('abfss://bronze@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Returns')

df_sales = spark.read.format('csv')\
    .option("header", True)\
    .option("inferSchema", True)\
    .load('abfss://bronze@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Sales*')

df_ter = spark.read.format('csv')\
    .option("header", True)\
    .option("inferSchema", True)\
    .load('abfss://bronze@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Territories')

df_subcat = spark.read.format('csv')\
    .option("header", True)\
    .option("inferSchema", True)\
    .load('abfss://bronze@<STORAGE_ACCOUNT>.dfs.core.windows.net/Product_Subcategories')

### TRANSFORMATIONS
#### Calendar
df_cal.display()
df_cal = df_cal.withColumn('Month', month(col('Date')))\
               .withColumn('Year', year(col('Date')))
df_cal.display()

df_cal.write.format('parquet')\
    .mode('append')\
    .option("path", "abfss://silver@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Calendar")\
    .save()

#### Customers
df_cus.display()
df_cus = df_cus.withColumn("fullName", concat_ws(' ', col('Prefix'), col('FirstName'), col('LastName')))
df_cus.display()

df_cus.write.format('parquet')\
    .mode('append')\
    .option("path", "abfss://silver@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Customers")\
    .save()

### Product Categories
df_procat.display()

#### Products
df_pro.display()
df_pro = df_pro.withColumn('ProductSKU', split(col('ProductSKU'),'-')[0])\
               .withColumn('ProductName', split(col('ProductName'),' ')[0])
df_pro.display()

df_pro.write.format('parquet')\
    .mode('append')\
    .option("path", "abfss://silver@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Products")\
    .save()

#### Returns
df_ret.display()
df_ret.write.format('parquet')\
    .mode('append')\
    .option("path", "abfss://silver@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Returns")\
    .save()

#### Sales
df_sales.display()
df_sales = df_sales.withColumn('StockDate', to_timestamp('StockDate'))
df_sales = df_sales.withColumn('OrderNumber', regexp_replace(col('OrderNumber'),'S','T'))
df_sales = df_sales.withColumn('multiple', col('OrderLineItem')*col('OrderQuantity'))
df_sales.display()

df_sales.write.format('parquet')\
    .mode('append')\
    .option("path", "abfss://silver@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Sales")\
    .save()

##### Sales Analysis
df_sales.groupBy('OrderDate').agg(count('OrderNumber')).alias('total_order').display()

#### Territories
df_ter.display()
df_ter.write.format('parquet')\
    .mode('append')\
    .option("path", "abfss://silver@<STORAGE_ACCOUNT>.dfs.core.windows.net/AdventureWorks_Territories")\
    .save()

#### Subcategories
df_subcat.display()
df_subcat.write.format('parquet')\
    .mode('append')\
    .option("path", "abfss://silver@<STORAGE_ACCOUNT>.dfs.core.windows.net/Product_Subcategories")\
    .save()
